{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d23701c",
   "metadata": {},
   "source": [
    "# Evaluation of Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcface96",
   "metadata": {},
   "source": [
    "Based on the same dataset used on previous weeks, let us evaluate the Collaborative Filtering (CF) models implemented last week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f5b50d",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "1. Load the test set and the predictions made with both Collaborative Filtering models in the previous session. \n",
    "2. Detect those users which are in the training set but not in the test set. Remove their predictions before evaluating the systems.\n",
    "3. Report the Root Mean Square Error (RMSE) for both CF models defined in the previous session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc4f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import SVD\n",
    "from surprise import KNNWithMeans\n",
    "import surprise\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75e6ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('All_Beauty_5.json.gz')\n",
    "\n",
    "df = df.sort_values(by=['reviewerID', 'asin', 'unixReviewTime'])\n",
    "cleaned_dataset = df.dropna(subset=['overall']).drop_duplicates(subset=['reviewerID', 'asin'], keep = 'last').reset_index(drop=True)\n",
    "# print(len(cleaned_dataset))\n",
    "# cleaned_dataset.head()\n",
    "cleaned_dataset = cleaned_dataset.sort_values(by=['reviewerID', 'unixReviewTime']).reset_index(drop=True)\n",
    "# extracting the latest (in time) positively rated item (rating  ≥4 ) by each user. \n",
    "test_data_pre = cleaned_dataset[cleaned_dataset.overall >= 4.0].drop_duplicates(subset=['reviewerID'], keep='last')\n",
    "# generate training data\n",
    "training_data = cleaned_dataset.drop(test_data_pre.index)\n",
    "\n",
    "# Remove users that do not appear in the training set.\n",
    "user_in_training = test_data_pre['reviewerID'].isin(training_data['reviewerID'])\n",
    "test_data = test_data_pre[user_in_training]\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "training = Dataset.load_from_df(training_data[['reviewerID', 'asin', 'overall']], reader=reader)\n",
    "testing = Dataset.load_from_df(test_data[['reviewerID', 'asin', 'overall']], reader=reader)\n",
    "\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': True  # compute  similarities between items\n",
    "               }\n",
    "\n",
    "algo_svd = SVD(n_epochs=500, n_factors=30, random_state=0)\n",
    "algo_knn = KNNWithMeans(k = 10 , sim_options = sim_options)\n",
    "\n",
    "trainset = training.build_full_trainset()\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73a72a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "There are 32 users in the training set that are not in the test set.\n",
      "54746\n",
      "54746\n",
      "RMSE: 0.7136\n",
      "0.7135826611787258\n",
      "RMSE: 0.8990\n",
      "0.8989955134770856\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# TEST\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# PREDICTIONS\n",
    "pred_nb_list = algo_knn.fit(trainset).test(testset)\n",
    "pred_lf_list = algo_svd.fit(trainset).test(testset)\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Detect users from training set that are not in test\n",
    "nb_users = set([pred.uid for pred in pred_nb_list])\n",
    "lf_users = set([pred.uid for pred in pred_lf_list])\n",
    "nb_users_in_pred_but_not_in_test = list(nb_users.difference(set(test_data['reviewerID'])))\n",
    "lf_users_in_pred_but_not_in_test = list(lf_users.difference(set(test_data['reviewerID'])))\n",
    "assert nb_users_in_pred_but_not_in_test == lf_users_in_pred_but_not_in_test\n",
    "print(f\"There are {len(lf_users_in_pred_but_not_in_test)} users in the training set that are not in the test set.\")\n",
    "print(len(pred_lf_list))\n",
    "print(len(pred_nb_list))\n",
    "print(surprise.accuracy.rmse(pred_lf_list))\n",
    "print(surprise.accuracy.rmse(pred_nb_list))\n",
    "# Remove these users' predictions for evaluation\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97632a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'surprise.prediction_algorithms.predictions.Prediction'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pred_lf_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "025c3d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rear_lf_list = []\n",
    "for i,name in enumerate(pred_lf_list):\n",
    "    if name.uid not in lf_users_in_pred_but_not_in_test:\n",
    "        rear_lf_list.append(pred_lf_list[i])\n",
    "\n",
    "rear_nb_list = []\n",
    "for i,name in enumerate(pred_nb_list):\n",
    "    if name.uid not in nb_users_in_pred_but_not_in_test:\n",
    "        rear_nb_list.append(pred_nb_list[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56384a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52988\n",
      "52988\n",
      "RMSE: 0.5486\n",
      "0.5485685650260251\n",
      "RMSE: 0.6856\n",
      "0.6855684531262348\n"
     ]
    }
   ],
   "source": [
    "print(len(rear_lf_list))\n",
    "print(len(rear_nb_list))\n",
    "print(surprise.accuracy.rmse(rear_lf_list))\n",
    "print(surprise.accuracy.rmse(rear_nb_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf3c25",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Define a general method to get the top-k recommendations for each user. Print the top-k with k={5, 10} recommendations for the user with ID 'ARARUVZ8RUF5T' and its estimated ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c95e3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B006IB5T4W', 5), ('B001F51RAG', 5), ('B00NT0AR7E', 5), ('B006WYJM8Y', 5), ('B00155Z6V2', 5), ('B00021DJ32', 4.993923352784167), ('B001QY8QXM', 4.948791090341968), ('B000X7ST9Y', 4.840934395462433), ('B00126LYJM', 4.839149265457805), ('B002RZZXYE', 4.834041803397214)]\n",
      "[('B000WR2HB6', 5), ('B000FOI48G', 4.675), ('B000VV1YOY', 4.666666666666667), ('B001ET7FZE', 4.6), ('B000PKKAGO', 4.5), ('B00EF1QRMU', 4.470205150915517), ('B016V8YWBC', 4.458333333333333), ('B00W259T7G', 4.42), ('B00CZH3K1C', 4.333333333333334), ('B000GLRREU', 4.233333333333333)]\n"
     ]
    }
   ],
   "source": [
    "def top_prediction(rank, pred_list, uid):\n",
    "    filted_pred_list = list(filter(lambda x: x.uid == uid, pred_list))\n",
    "    filted_pred_list.sort(key=lambda x: x.est, reverse=True)\n",
    "    return [(i.iid,i.est) for i in filted_pred_list][:rank]\n",
    "\n",
    "print(top_prediction(10, rear_lf_list, 'ARARUVZ8RUF5T'))\n",
    "print(top_prediction(10, rear_nb_list, 'ARARUVZ8RUF5T'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03325a14",
   "metadata": {},
   "source": [
    "## Excercise 3\n",
    "Report Precision@k (P@k), MAP@k and the MRR@k with k={5, 10, 20} averaged across users for both CF systems. When computing precision, we consider as relevant items those with an observed rating >= 4.0 (i.e., those items from the test set with a rating >= 4.0). Reflect on the differences obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64ea0b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_matrix = pd.DataFrame(columns = test_data['asin'].drop_duplicates(), index = test_data['reviewerID'].drop_duplicates())\n",
    "for row_i in range(len(test_data)):\n",
    "    reviewerID = list(test_data.reviewerID)[row_i]\n",
    "    asin = list(test_data.asin)[row_i]\n",
    "    rate = list(test_data.overall)[row_i]\n",
    "    relevant_matrix.loc[reviewerID, asin] = 1 if rate >= 4 else 0\n",
    "relevant_matrix = relevant_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb26be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def p_k_user(filted_pred_list, user_id, cut_off, relevant_matrix:pd.DataFrame):\n",
    "    summation = []\n",
    "    for i in range(cut_off):\n",
    "        item_id = filted_pred_list[i][0]\n",
    "        try:\n",
    "            summation.append(relevant_matrix.loc[user_id, item_id])\n",
    "        except KeyError:\n",
    "            summation.append(0)\n",
    "    return sum(summation)/float(cut_off)\n",
    "\n",
    "def ap_k_user(filted_pred_list, user_id, cut_off, relevant_matrix:pd.DataFrame):\n",
    "    num_relevance = sum(relevant_matrix.loc[user_id,:])\n",
    "    summation = []\n",
    "    for i in range(cut_off):\n",
    "        item_id = filted_pred_list[i][0]\n",
    "        try:\n",
    "            if relevant_matrix.loc[user_id, item_id] == 1:\n",
    "                summation.append(p_k_user(filted_pred_list, user_id, i+1, relevant_matrix))\n",
    "        except KeyError:\n",
    "            summation.append(0)\n",
    "    # if num_relevance == 0:\n",
    "    #     return 0\n",
    "    return sum(summation)/float(num_relevance)\n",
    "\n",
    "def rr_k_user(filted_pred_list, user_id, cut_off, relevant_matrix:pd.DataFrame):\n",
    "    for i in range(cut_off):\n",
    "        item_id = filted_pred_list[i][0]\n",
    "        try:\n",
    "            if relevant_matrix.loc[user_id, item_id] == 1:\n",
    "                return 1/float(i+1)\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return 0\n",
    "\n",
    "def hr_k_user(filted_pred_list, user_id, cut_off, relevant_matrix:pd.DataFrame):\n",
    "    for i in range(cut_off):\n",
    "        item_id = filted_pred_list[i][0]\n",
    "        try:\n",
    "            if relevant_matrix.loc[user_id, item_id] == 1:\n",
    "                return 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return 0\n",
    "\n",
    "def mean_k(pred_list, cut_off, function, relevant_matrix:pd.DataFrame):\n",
    "    user_list = []\n",
    "    user_list = [item.uid for item in pred_list if item.uid not in user_list]\n",
    "    num_users = len(relevant_matrix.index)\n",
    "    summation = []\n",
    "    user_item_rating = defaultdict(list)\n",
    "    for pred in pred_list:\n",
    "        user_item_rating[pred.uid].append((pred.iid, pred.est))\n",
    "    for user_id, filted_pred_list in user_item_rating.items():\n",
    "        filted_pred_list.sort(key=lambda x: x[1], reverse=True)\n",
    "        summation.append(function(filted_pred_list, user_id, cut_off, relevant_matrix))\n",
    "    return sum(summation)/float(num_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca4a3fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14794520547945267\n",
      "0.1674569722514925\n",
      "0.1674569722514925\n"
     ]
    }
   ],
   "source": [
    "print(mean_k(rear_nb_list, 5, p_k_user, relevant_matrix))\n",
    "print(mean_k(rear_nb_list, 5, ap_k_user, relevant_matrix))\n",
    "print(mean_k(rear_nb_list, 5, rr_k_user, relevant_matrix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4c50b",
   "metadata": {},
   "source": [
    "## Excercise 4\n",
    "\n",
    "Based on the top-5, top-10 and top-20 predictions from Exercise 2, compute the systems’ hit rate averaged over the total number of users in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "062588c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7397260273972602\n"
     ]
    }
   ],
   "source": [
    "print(mean_k(rear_nb_list, 5, hr_k_user, relevant_matrix))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae6011ca",
   "metadata": {},
   "source": [
    "# Content-based recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a455b8a",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "Based on the TF-IDF vectors obtained in the Exercise 2 from Session 4, represent each user in the same vector space. Amongst other feasible solutions, you can represent a user (user profile) by computing the weighted mean of the items vectors. Compute the cosine similarity for user 'A39WWMBA0299ZF' and all products in the training set not rated by the user. What are the top-5 recommended items for user 'A39WWMBA0299ZF'? Print out the top-5 items and their similarity score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6de5e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summary import Contentbased_recommendation, Evaluation\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def getDF(path):\n",
    "    def parse(path):\n",
    "        g = gzip.open(path, 'rb')\n",
    "        for l in g:\n",
    "            yield json.loads(l)\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df_1 = getDF('All_Beauty_5.json.gz')\n",
    "df_2 = pd.read_json('meta_All_Beauty.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b005e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Contentbased_recommendation(ui_df=df_1, item_df=df_2)\n",
    "predicetion_list = preprocess.predection()\n",
    "evaluation = Evaluation(predicetion_list, df_1, df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69af5fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B019FWRG3C', array([0.4158461])), ('B00W259T7G', array([0.17710348])), ('B019809F9Y', array([0.10437818])), ('B00IJHY54S', array([0.08747406])), ('B0006O10P4', array([0.08561345]))]\n"
     ]
    }
   ],
   "source": [
    "print(evaluation.rank_k(uid='A39WWMBA0299ZF',rank=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f2bbe",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7805a3",
   "metadata": {},
   "source": [
    "Compute the systemsâ€™ hit rate based on the top-5, top-10 and top-20 recommendations, averaged over the total number of users. Remember that, as we are evaluating the system, you should compute the hit rate over the test set. How well/bad does this Content-based approach perform compared to the Collaborative Filtering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec627f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kr_mean_5 = evaluation.mean_k(5, 'hr_k')\n",
    "kr_mean_10 = evaluation.mean_k(10, 'hr_k')\n",
    "kr_mean_20 = evaluation.mean_k(20, 'hr_k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd4b23d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4320337197049526\n",
      "0.45732349841938885\n",
      "0.5163329820864068\n"
     ]
    }
   ],
   "source": [
    "print(kr_mean_5)\n",
    "print(kr_mean_10)\n",
    "print(kr_mean_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d74d43",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Repeat Exercise 1 and 2, this time representing the products and users in a word2vec vector space. You may use the gensim library and download the 300-dimension embeddings from Google. Source: https://radimrehurek.com/gensim/models/word2vec.html#pretrained-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca33a843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "word2vec_vectors = gensim.downloader.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a09f04b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4077976817702845\n"
     ]
    }
   ],
   "source": [
    "import summary\n",
    "from summary import Contentbased_recommendation, Evaluation\n",
    "df_1, df_2 = summary.ini()\n",
    "preprocess = Contentbased_recommendation(ui_df=df_1, item_df=df_2, word2vec=True)\n",
    "predicetion_list = preprocess.prediction()\n",
    "evaluation = Evaluation(predicetion_list, df_1, df_2)\n",
    "kr_mean_5 = evaluation.mean_k(5, 'hr_k')\n",
    "print(kr_mean_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a38279e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B019FWRG3C', array([0.76013947])), ('B000W0C07Y', array([0.74363018])), ('B0012Y0ZG2', array([0.73555437])), ('B0009RF9DW', array([0.70102609])), ('B000LIBUBY', array([0.70102479]))]\n"
     ]
    }
   ],
   "source": [
    "print(evaluation.rank_k()['A39WWMBA0299ZF'][:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
